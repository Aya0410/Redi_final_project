# Redi_final_project

# Data Analyst Job Market Analysis

## Description

This project analyzes the job market for data analysts by collecting job postings and performing data analysis and machine learning techniques. It aims to provide insights into the skills, tools, and salaries associated with data analyst positions.

## Table of Contents

- [Installation](#installation)
- [Usage](#usage)
- [Data](#data)
- [Visualization](#visualization)
- [Machine Learning](#machine-learning)

## Installation

To use this project, you need to have Python and the required dependencies installed. You can install the necessary dependencies using the following command:


## Usage

To use the project, follow these steps:

1. Clone the repository.
2. Install the required dependencies.
3. Run the data collection script to gather job postings.
4. Run the data analysis and visualization scripts to explore the job market.
5. Run the machine learning scripts to build predictive models.
6. Modify the code and customize it according to your requirements.

## Data

The dataset used in this project consists of job postings for data analyst positions. It includes information such as job titles, descriptions, salaries, and locations. The dataset has been preprocessed to handle missing values and standardized salary information.

## Visualization

The project includes various visualizations to analyze the data. Some of the visualizations used are:

- Histograms of average data analyst pay, annual salary, and hourly pay.
- Bar charts showing the top tools and skills for data analysts.

These visualizations provide insights into salary distributions, popular tools, and skills in the data analyst job market.

## Machine Learning

Two machine learning models have been implemented in this project:

1. Random Forest: This model is used to predict salary ranges based on job descriptions and other features.
2. CatBoost: Another model used for salary prediction, leveraging gradient boosting techniques.

The data is preprocessed, features are extracted, and the models are trained and evaluated using appropriate evaluation metrics.



## Acknowledgements

- The project relies on the NLTK library for tokenization and analysis.
- The visualizations are created using Matplotlib and Seaborn.
- The machine learning models utilize scikit-learn, CatBoost, and other related libraries.




